# ğŸ›’ PriceCompare â€” Product Price Comparison Website

A full-stack web application that allows users to compare prices of electronic products (phones, laptops, computers) across different online stores.

The system collects product information using web scraping, stores normalized product data in a database, and displays current prices through a modern web interface.

---

## âœ¨ Features

* ğŸ” Search products across stores
* ğŸ’° Compare prices in one place
* ğŸ–¥ Modern Apple/Wealthsimple-style UI
* ğŸ¤– Backend ready for AI-based product categorization
* ğŸŒ REST API between frontend and backend
* ğŸ—„ Database storage for products and prices

---

## ğŸ— System Architecture

```
User Browser (React Frontend)
            â†“ API Requests
        Flask Backend API
            â†“
        SQLite Database
            â†‘
     Selenium Scraper (Data Collector)
```

### Components

#### Frontend

* React (UI framework)
* TailwindCSS (styling)
* Axios (API communication)

#### Backend

* Python
* Flask (REST API)
* Selenium (web scraping)
* SQLite (database)

---

## ğŸ“ Project Structure

```
price-compare-app/
â”‚
â”œâ”€â”€ backend/
â”‚   â”œâ”€â”€ app.py            # Flask API server
â”‚   â”œâ”€â”€ database.py       # Database logic
â”‚   â”œâ”€â”€ scraper.py        # Scraper + data insertion
â”‚   â”œâ”€â”€ products.db       # SQLite database
â”‚   â””â”€â”€ requirements.txt
â”‚
â”œâ”€â”€ frontend/
â”‚   â”œâ”€â”€ src/
â”‚   â”‚   â”œâ”€â”€ components/
â”‚   â”‚   â”‚   â”œâ”€â”€ Header.jsx
â”‚   â”‚   â”‚   â”œâ”€â”€ Footer.jsx
â”‚   â”‚   â”‚   â””â”€â”€ ProductCard.jsx
â”‚   â”‚   â””â”€â”€ App.jsx
â”‚   â””â”€â”€ .env
â”‚
â””â”€â”€ README.md
```

---

## âš™ï¸ Installation Guide

### 1ï¸âƒ£ Clone Repository

```
git clone <your-repo-url>
cd price-compare-app
```

---

## ğŸ Backend Setup (Python + Flask)

### Step 1 â€” Create Virtual Environment

```
cd backend
python -m venv venv
```

Activate environment:

**Windows**

```
venv\Scripts\activate
```

**Mac/Linux**

```
source venv/bin/activate
```

---

### Step 2 â€” Install Dependencies

```
pip install flask flask-cors selenium
pip freeze > requirements.txt
```

---

### Step 3 â€” Initialize Database & Insert Sample Data

```
python scraper.py
```

This will:

* create `products.db`
* insert example products
* simulate scraping

---

### Step 4 â€” Run Backend Server

```
python app.py
```

Backend runs at:

```
http://localhost:5000
```

Test API:

```
http://localhost:5000/products
```

You should see JSON product data.

---

## âš›ï¸ Frontend Setup (React)

### Step 1 â€” Install Dependencies

```
cd frontend
npm install
```

---

### Step 2 â€” Configure Environment Variables

Create `.env` file inside `frontend/`:

```
REACT_APP_API_URL=http://localhost:5000
```

---

### Step 3 â€” Run Frontend

```
npm start
```

Open browser:

```
http://localhost:3000
```

---

## ğŸ”„ Development Workflow

Typical workflow:

1. Run scraper â†’ collects products
2. Store data in database
3. Backend exposes API endpoints
4. Frontend fetches and displays products

---

## ğŸ¤– Scraper Overview

`scraper.py` is responsible for:

* Visiting store websites
* Extracting:

  * product name
  * price
  * store name
  * link
  * image
* Saving data into the database

Future scrapers can be added per store:

```
scrape_bestbuy()
scrape_amazon()
scrape_newegg()
```

---

## ğŸ“ˆ Scaling Plan

### Backend Scaling

* Replace Flask â†’ FastAPI
* Add async scraping jobs
* Schedule scrapers using cron or Celery
* Move SQLite â†’ PostgreSQL

### Frontend Scaling

* Add routing (React Router)
* Product detail pages
* Filters & sorting
* User accounts

### Infrastructure

* Frontend â†’ Vercel / Netlify
* Backend â†’ Render / AWS
* Database â†’ Supabase / PostgreSQL

---

## ğŸ§  Future AI Features

Planned AI integrations:

* Product name normalization
* Feature extraction from descriptions
* Automatic product matching across stores
* Price trend prediction

---

## ğŸ›  Troubleshooting

### Products not showing

* Ensure backend is running on port 5000
* Restart React after editing `.env`
* Check browser console for Axios errors

### Database empty

Run:

```
python scraper.py
```

---

## ğŸ‘¨â€ğŸ’» Author

Built by **Huseyn Talibov**

---

## ğŸ“„ License

MIT License â€” free to modify and use.
